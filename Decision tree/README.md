## Decision tree 決策樹
可做分類或預測
從訓練資料當中尋找規則並建立一棵樹，利用樹的分支概念獲得預測結果，
主要將每一個分支的決策使訊息增益最大化
ex. 吃飯選餐廳，會考量到價格、口碑、菜單，台灣普遍都相信評論口碑，
因此在餐廳的首選，可能就會先考慮口碑的好壞
再來就是菜單是不是想要吃的，
最後才會考慮到價格的部分。
所以今天發現餐廳的口碑不好，連選都不選直接排除了。
---
如何生成
從上述介紹中就可明白，以貪婪法則來決定每層詢問之事項
再者依靠亂度的評估指標來判斷決策的好壞
**亂度評估指標**
指的是應用客觀的標準來決定決策樹的每個分支
常見的有
- Information Gain 資訊獲利
- Gini Index or Gini Impurity 吉尼係數

Information Gain
計算熵，將決策樹分割後獲得之資訊越好越好

Gini Impurity
數字越大代表序列資料越亂

決策樹以亂度評估生成的指標，最後用 MSA、MAE評估決策樹模型，
SKlearn 決策樹套件都是採用 **CART(classification and regression tree)**

優點:
- 簡單明瞭、高度可解釋性
- 計算時間複雜度
- 幾乎沒有要調整的超參數
缺點，容易 overfitting
---
**總結**
深度越深，規則就越複雜，較容易真實的data，但也容易產生雜訊而造成error
集成學習中的 Boosting 架構
